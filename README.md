# Data-Bias
The goal of this project is to explore the concept of bias through querying an existing natural language processing model â€” specifically, the Perspective API released by Google Jigsaw. 

  My hyptothesis was that Perspective API's model is more bias towards comments using direct langauge and verbage. For example comments with phrases such as "you are" or "he is" will genrally result in higher toxicity scores than comments using less or no direct language. In order to test this hypothesis I pulled thirteen comments from the sammple data and found the toxicity score of each one. I then re wrote every comment in a new data frame. If the comment used direct language I re-wrote without direct language and if didn't use direct langauge I re-wrote using direct langauge. I then found the toxicity score of the new comments that I had written as well as calculated the difference between the new and old toxicities. 
  For the purpose of this test my threshold for what is considered a toxic comment is 50% and decided a change in toxicity of 3% was considered statistically significant. I also decided if more than half of the comments had a signifcant change in toxicity I can declare my hypotheis to be true. Out of the thirteen comments, seven of them had significant change in toxicity when direct language was either removed or added. seven out of thirteen comments gives us a 53.8% which is above my threshold therefore my hypthesis has been declared infact true. I also believe the success rate would be higher using a bigger sample size.
   After conducting my test it is pretty clear to me that after conducting this test that Perspective API is very biased towards comments using direct language. To even further prove my hypothesis true I conduced a small second test. I gathered some of the most hurtful toxic comments I could find(going by context not score)and compared them to short comments using direct langauge. For example the comment "we hate america and we are going to bomb the shit out of there cities Quezas will rain" had a toxicity score of 85% which was lower than the comment "You are stupid" which had a toxicity score of 91%. This is true for other pairs of comments I tested. This is also tells me the Persepcitve API is not great about picking up context as a comment like "I want to go shoot a school full of kids up" is really awful and toxic comment yet only has a toxicity of 75% compared to "He is a dumb dumb" which has a score of 85%. It appears that since the school shooting comment doesn't actually have any really bad individual words could be the reason why the score isn't higher. However, A.I. is becoming increasinly intelligent and APIs such as google's perspecitce will eventually catch up and grow with time. We already have A.I. systems in place like chat GPT and GPT 4 has just come out so its definitely here to stay and will only become better.
